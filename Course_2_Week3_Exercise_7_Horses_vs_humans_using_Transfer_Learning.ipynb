{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course 2 - Week3 - Exercise 7 - Horses vs. humans using Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackiekuen2/coursera-tensorflow/blob/master/Course_2_Week3_Exercise_7_Horses_vs_humans_using_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "caa09c96-36a2-40b8-c397-a02843ae8a30"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-25 15:48:48--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.161.80, 2404:6800:4004:80e::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.161.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  84.8MB/s    in 1.0s    \n",
            "\n",
            "2019-08-25 15:48:50 (84.8 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 15:48:50.908462 140375244687232 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "650f6629-1562-4bb2-a69f-67f3d99c1c75"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "229bf837-b9e1-4015-f99e-2ecd1aa14c27"
      },
      "source": [
        "# from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                 \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = Adam(lr=0.0001), \n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0825 15:49:01.214548 140375244687232 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "23121d83-f270-4e6e-f81c-366dc40632fb"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-25 15:49:02--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.161.48, 2404:6800:4004:808::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.161.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   117MB/s    in 1.2s    \n",
            "\n",
            "2019-08-25 15:49:04 (117 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-08-25 15:49:05--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.161.48, 2404:6800:4004:808::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.161.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-08-25 15:49:05 (172 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1d23155f-6079-49c2-f3fb-233c96339055"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses')\n",
        "train_humans_dir = os.path.join(train_dir, 'humans')\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "33fbb285-d1b2-47ad-c524-f0aaa1bd4259"
      },
      "source": [
        "\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')  \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(\n",
        "    validation_dir, \n",
        "    target_size=(150, 150), \n",
        "    batch_size=20, \n",
        "    class_mode='binary')\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c15b64ec-496e-46ba-b2f5-08d179a84c8e"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch = 100,\n",
        "    epochs = 100,\n",
        "    validation_steps = 50,\n",
        "    verbose = 1,\n",
        "    callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.1686 - acc: 0.9250 - val_loss: 0.0022 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.0507 - acc: 0.9829 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0486 - acc: 0.9801 - val_loss: 0.0055 - val_acc: 0.9960\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0416 - acc: 0.9818 - val_loss: 0.0081 - val_acc: 0.9960\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0237 - acc: 0.9899 - val_loss: 0.0275 - val_acc: 0.9889\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0311 - acc: 0.9893 - val_loss: 0.0160 - val_acc: 0.9919\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0272 - acc: 0.9925 - val_loss: 0.0077 - val_acc: 0.9960\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0338 - acc: 0.9899 - val_loss: 5.3029e-05 - val_acc: 1.0000\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 21s 215ms/step - loss: 0.0179 - acc: 0.9934 - val_loss: 8.1434e-04 - val_acc: 1.0000\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 21s 213ms/step - loss: 0.0134 - acc: 0.9954 - val_loss: 3.7960e-04 - val_acc: 1.0000\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 21s 213ms/step - loss: 0.0248 - acc: 0.9909 - val_loss: 6.0900e-05 - val_acc: 1.0000\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0390 - acc: 0.9884 - val_loss: 1.5196e-04 - val_acc: 1.0000\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 21s 215ms/step - loss: 0.0207 - acc: 0.9924 - val_loss: 2.9749e-04 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0389 - acc: 0.9873 - val_loss: 2.0862e-05 - val_acc: 1.0000\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.0194 - acc: 0.9929 - val_loss: 9.8924e-06 - val_acc: 1.0000\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0355 - acc: 0.9930 - val_loss: 1.9860e-05 - val_acc: 1.0000\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0183 - acc: 0.9949 - val_loss: 0.0164 - val_acc: 0.9960\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.0100 - acc: 0.9965 - val_loss: 0.0092 - val_acc: 0.9960\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0394 - acc: 0.9889 - val_loss: 3.0950e-04 - val_acc: 1.0000\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0091 - acc: 0.9960 - val_loss: 0.0162 - val_acc: 0.9960\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0169 - acc: 0.9944 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 21s 215ms/step - loss: 0.0221 - acc: 0.9939 - val_loss: 0.0333 - val_acc: 0.9960\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.0274 - acc: 0.9929 - val_loss: 0.0582 - val_acc: 0.9879\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0274 - acc: 0.9909 - val_loss: 0.0575 - val_acc: 0.9879\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 22s 215ms/step - loss: 0.0102 - acc: 0.9965 - val_loss: 0.0227 - val_acc: 0.9960\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 21s 215ms/step - loss: 0.0391 - acc: 0.9878 - val_loss: 0.0484 - val_acc: 0.9960\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0192 - acc: 0.9954 - val_loss: 0.2066 - val_acc: 0.9727\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.0196 - acc: 0.9949 - val_loss: 0.0793 - val_acc: 0.9848\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0188 - acc: 0.9944 - val_loss: 0.0073 - val_acc: 0.9970\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0104 - acc: 0.9970 - val_loss: 0.0378 - val_acc: 0.9960\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.0158 - acc: 0.9964 - val_loss: 0.0418 - val_acc: 0.9960\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0227 - acc: 0.9924 - val_loss: 0.0217 - val_acc: 0.9960\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.0147 - acc: 0.9944 - val_loss: 0.0488 - val_acc: 0.9960\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0330 - acc: 0.9899 - val_loss: 0.0416 - val_acc: 0.9960\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.0086 - acc: 0.9970 - val_loss: 0.0213 - val_acc: 0.9960\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 21s 213ms/step - loss: 0.0190 - acc: 0.9944 - val_loss: 0.5531 - val_acc: 0.9474\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 21s 215ms/step - loss: 0.0207 - acc: 0.9955 - val_loss: 0.0788 - val_acc: 0.9889\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 21s 213ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0542 - val_acc: 0.9960\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.0212 - acc: 0.9954 - val_loss: 0.0527 - val_acc: 0.9960\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.0171 - acc: 0.9954 - val_loss: 0.0198 - val_acc: 0.9960\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0046 - acc: 0.9975 - val_loss: 0.0755 - val_acc: 0.9919\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.0123 - acc: 0.9960 - val_loss: 0.0844 - val_acc: 0.9879\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.0154 - acc: 0.9969 - val_loss: 0.1391 - val_acc: 0.9838\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0567 - val_acc: 0.9919\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 21s 213ms/step - loss: 0.0285 - acc: 0.9924 - val_loss: 0.0976 - val_acc: 0.9919\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0194 - acc: 0.9949 - val_loss: 0.0876 - val_acc: 0.9919\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.0077 - acc: 0.9985 - val_loss: 0.0972 - val_acc: 0.9889\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0131 - acc: 0.9959 - val_loss: 0.0835 - val_acc: 0.9879\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.0189 - acc: 0.9965 - val_loss: 0.0383 - val_acc: 0.9919\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.0189 - acc: 0.9975 - val_loss: 0.0295 - val_acc: 0.9960\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.0060 - acc: 0.9969 - val_loss: 0.0887 - val_acc: 0.9919\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.0055 - acc: 0.9980 - val_loss: 0.1076 - val_acc: 0.9879\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 20s 204ms/step - loss: 0.0050 - acc: 0.9980 - val_loss: 0.0829 - val_acc: 0.9909\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.0171 - acc: 0.9944 - val_loss: 0.1097 - val_acc: 0.9889\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.0167 - acc: 0.9949 - val_loss: 0.1107 - val_acc: 0.9858\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.0146 - acc: 0.9949 - val_loss: 0.0942 - val_acc: 0.9858\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0060 - acc: 0.9975 - val_loss: 0.0954 - val_acc: 0.9838\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.0140 - acc: 0.9964 - val_loss: 0.0858 - val_acc: 0.9879\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.0087 - acc: 0.9975 - val_loss: 0.0998 - val_acc: 0.9848\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.0200 - acc: 0.9959 - val_loss: 0.2554 - val_acc: 0.9767\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.0392 - acc: 0.9909 - val_loss: 0.0498 - val_acc: 0.9960\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0390 - val_acc: 0.9960\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0874 - val_acc: 0.9858\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0240 - val_acc: 0.9960\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.0216 - acc: 0.9924 - val_loss: 0.0556 - val_acc: 0.9919\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.0206 - acc: 0.9949 - val_loss: 0.0431 - val_acc: 0.9899\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0469 - val_acc: 0.9879\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.1778 - val_acc: 0.9838\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.0227 - acc: 0.9965 - val_loss: 0.0138 - val_acc: 0.9960\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0065 - acc: 0.9985 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0298 - val_acc: 0.9960\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0130 - acc: 0.9949 - val_loss: 0.0165 - val_acc: 0.9960\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0078 - acc: 0.9959 - val_loss: 0.0828 - val_acc: 0.9879\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.0337 - acc: 0.9940 - val_loss: 0.0852 - val_acc: 0.9879\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.0389 - acc: 0.9924 - val_loss: 0.0307 - val_acc: 0.9960\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.0067 - acc: 0.9970 - val_loss: 0.0967 - val_acc: 0.9889\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 0.0683 - val_acc: 0.9889\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.0173 - acc: 0.9935 - val_loss: 0.0623 - val_acc: 0.9879\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 21s 206ms/step - loss: 0.0026 - acc: 0.9985 - val_loss: 0.0185 - val_acc: 0.9960\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.0051 - acc: 0.9990 - val_loss: 0.0791 - val_acc: 0.9879\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0271 - val_acc: 0.9960\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.0135 - acc: 0.9949 - val_loss: 0.0748 - val_acc: 0.9879\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.0119 - acc: 0.9970 - val_loss: 0.1831 - val_acc: 0.9798\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.0090 - acc: 0.9980 - val_loss: 0.1446 - val_acc: 0.9848\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 21s 213ms/step - loss: 0.0183 - acc: 0.9954 - val_loss: 0.1859 - val_acc: 0.9838\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.0212 - acc: 0.9929 - val_loss: 0.0842 - val_acc: 0.9848\n",
            "Epoch 87/100\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9995\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.0039 - acc: 0.9995 - val_loss: 0.1768 - val_acc: 0.9838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "322838b1-5b0b-444e-ed4c-f583471f824c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}